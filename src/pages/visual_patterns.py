"""
Visual Patterns Page
Displays visual feature analysis and patterns - COMPLETE IMPLEMENTATION
"""
import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import numpy as np
import json
from pathlib import Path
import sys

sys.path.append(str(Path(__file__).parent.parent.parent))
from src.utils.lazy_loader import LazyLoader
from src.utils.visualization_helpers import (
    create_box_plot,
    create_heatmap,
    calculate_statistics,
    add_statistical_annotations,
    CHART_CONFIG
)

lazy_loader = LazyLoader()


def render_visual_patterns(container):
    """Render Visual Patterns with lazy loading - COMPLETE IMPLEMENTATION"""
    with container.container():
        try:
            st.header("Visual Characteristics: Fake vs Real Images")
            
            st.markdown("""
            **Key Questions Answered:**
            - Do fake and real images have different visual characteristics?
            - What visual features best distinguish authentic from inauthentic content?
            - How do image quality metrics correlate with authenticity?
            """)
            
            # Load from JSON summary (FULL dataset with pre-computed visualizations)
            @st.cache_data(ttl=600)  # Cache for 10 minutes
            def load_visual_features_from_json():
                import json
                
                summary_path = Path('analysis_results/dashboard_data/visual_features_summary.json')
                
                if not summary_path.exists():
                    raise FileNotFoundError(f"Visual features summary not found at {summary_path}")
                
                with open(summary_path, 'r') as f:
                    summary = json.load(f)
                
                return summary
            
            summary = load_visual_features_from_json()
            
            # Hide loading indicator after all data is loaded
            lazy_loader.hide_section_loading()
            
            # Extract metadata
            total_records = summary.get('total_records', 0)
            fake_count = summary.get('fake_count', 0)
            real_count = summary.get('real_count', 0)
            
            if total_records > 0:
                # Overall visual analysis metrics
                st.subheader("üìä Visual Analysis Overview")
                
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("üñºÔ∏è Total Images Analyzed", f"{total_records:,}")
                
                with col2:
                    st.metric("üî¥ Fake Images", f"{fake_count:,}", 
                             delta=f"{fake_count/total_records*100:.1f}%")
                
                with col3:
                    st.metric("üü¢ Real Images", f"{real_count:,}", 
                             delta=f"{real_count/total_records*100:.1f}%")
                
                with col4:
                    # Calculate processing success from features_by_authenticity if available
                    st.metric("‚úÖ Full Dataset", "100%", help="Using complete dataset with pre-computed visualizations")
                
                # 1. Feature Distribution Grid (2x2: brightness, sharpness, entropy, noise level)
                st.subheader("üìä Feature Distribution Grid")
                st.markdown("Comparing distributions of key visual features between fake and real images")
                
                feature_columns = {
                    'mean_brightness': 'Brightness',
                    'sharpness_score': 'Sharpness',
                    'visual_entropy': 'Visual Entropy',
                    'noise_level': 'Noise Level'
                }
                
                # Create 2x2 subplot grid
                fig_grid = make_subplots(
                    rows=2, cols=2,
                    subplot_titles=list(feature_columns.values()),
                    vertical_spacing=0.20,
                    horizontal_spacing=0.12
                )
                
                positions = [(1, 1), (1, 2), (2, 1), (2, 2)]
                histograms = summary.get('histograms', {})
                
                for (feature_col, feature_name), (row, col) in zip(feature_columns.items(), positions):
                    if feature_col in histograms:
                        hist_data = histograms[feature_col]
                        
                        # Add fake histogram from pre-computed data
                        if 'fake' in hist_data:
                            fake_hist = hist_data['fake']
                            bin_centers = [(fake_hist['bin_edges'][i] + fake_hist['bin_edges'][i+1]) / 2 
                                          for i in range(len(fake_hist['bin_edges']) - 1)]
                            
                            fig_grid.add_trace(
                                go.Bar(
                                    x=bin_centers,
                                    y=fake_hist['counts'],
                                    name='Fake',
                                    marker_color=CHART_CONFIG['colors']['fake'],
                                    opacity=0.6,
                                    legendgroup='fake',
                                    showlegend=(row == 1 and col == 1)
                                ),
                                row=row, col=col
                            )
                        
                        # Add real histogram from pre-computed data
                        if 'real' in hist_data:
                            real_hist = hist_data['real']
                            bin_centers = [(real_hist['bin_edges'][i] + real_hist['bin_edges'][i+1]) / 2 
                                          for i in range(len(real_hist['bin_edges']) - 1)]
                            
                            fig_grid.add_trace(
                                go.Bar(
                                    x=bin_centers,
                                    y=real_hist['counts'],
                                    name='Real',
                                    marker_color=CHART_CONFIG['colors']['real'],
                                    opacity=0.6,
                                    legendgroup='real',
                                    showlegend=(row == 1 and col == 1)
                                ),
                                row=row, col=col
                            )
                        
                        # Update axes labels
                        fig_grid.update_xaxes(title_text=feature_name, row=row, col=col)
                        fig_grid.update_yaxes(title_text='Count', row=row, col=col)
                
                fig_grid.update_layout(
                    height=600,
                    barmode='overlay',
                    title_text="Visual Feature Distributions: Fake vs Real",
                    showlegend=True,
                    legend=dict(
                        orientation='h',
                        yanchor='bottom',
                        y=1.02,
                        xanchor='right',
                        x=1
                    )
                )
                
                st.plotly_chart(fig_grid, use_container_width=True)
                
                # 2. Visual Feature Correlation Matrix
                st.subheader("üîó Visual Feature Correlation Matrix")
                st.markdown("Correlation between visual features calculated from full dataset")
                
                # Calculate correlation from pre-computed statistics
                correlation_features = [
                    'mean_brightness', 'sharpness_score', 'visual_entropy', 'noise_level',
                    'contrast_score', 'color_diversity', 'edge_density'
                ]
                
                features_by_auth = summary.get('features_by_authenticity', {})
                
                # Build correlation matrix from statistics (simplified approach)
                # Note: True correlation requires covariance, but we can show feature relationships
                st.info("üí° Correlation analysis requires raw data. Showing feature statistics comparison instead.")
                
                # Show feature comparison table
                comparison_data = []
                for feature in correlation_features:
                    if feature in features_by_auth.get('fake', {}) and feature in features_by_auth.get('real', {}):
                        fake_stats = features_by_auth['fake'][feature]
                        real_stats = features_by_auth['real'][feature]
                        
                        comparison_data.append({
                            'Feature': feature.replace('_', ' ').title(),
                            'Fake Mean': f"{fake_stats['mean']:.3f}",
                            'Real Mean': f"{real_stats['mean']:.3f}",
                            'Difference': f"{((fake_stats['mean'] - real_stats['mean']) / real_stats['mean'] * 100):+.1f}%"
                        })
                
                if comparison_data:
                    st.dataframe(pd.DataFrame(comparison_data), use_container_width=True)
                
                # 3. Manipulation Score Box Plots
                st.subheader("üì¶ Manipulation Score Analysis")
                st.markdown("Statistical comparison of manipulation scores between fake and real images (full dataset)")
                
                boxplot_data = summary.get('boxplot_data', {})
                
                if 'manipulation_score' in boxplot_data:
                    # Create box plot from pre-computed data
                    fig_box = go.Figure()
                    
                    for label_name, color in [('fake', CHART_CONFIG['colors']['fake']), 
                                             ('real', CHART_CONFIG['colors']['real'])]:
                        if label_name in boxplot_data['manipulation_score']:
                            box_stats = boxplot_data['manipulation_score'][label_name]
                            
                            fig_box.add_trace(go.Box(
                                name=label_name.capitalize(),
                                q1=[box_stats['q1']],
                                median=[box_stats['median']],
                                q3=[box_stats['q3']],
                                lowerfence=[box_stats['min']],
                                upperfence=[box_stats['max']],
                                y=box_stats.get('outliers', []),
                                marker_color=color,
                                boxmean='sd'
                            ))
                    
                    fig_box.update_layout(
                        title='Manipulation Score Distribution: Fake vs Real (Full Dataset)',
                        yaxis_title='Manipulation Score',
                        height=500
                    )
                    st.plotly_chart(fig_box, use_container_width=True)
                    
                    # Show statistics from pre-computed data
                    fake_stats = features_by_auth.get('fake', {}).get('manipulation_score', {})
                    real_stats = features_by_auth.get('real', {}).get('manipulation_score', {})
                    
                    if fake_stats and real_stats:
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Fake Mean", f"{fake_stats.get('mean', 0):.3f}")
                        with col2:
                            st.metric("Real Mean", f"{real_stats.get('mean', 0):.3f}")
                        with col3:
                            fake_mean = fake_stats.get('mean', 0)
                            real_mean = real_stats.get('mean', 0)
                            diff_pct = ((fake_mean - real_mean) / real_mean * 100) if real_mean != 0 else 0
                            st.metric("Difference", f"{diff_pct:+.1f}%")
                else:
                    st.warning("Manipulation score data not available")
                
                # 4. Top Discriminative Features Analysis
                st.subheader("üéØ Top Discriminative Features")
                st.markdown("Features with largest differences between fake and real images (full dataset)")
                
                # Calculate discriminative features from pre-computed statistics
                discriminative_features = []
                
                for feature_col, feature_name in feature_columns.items():
                    if feature_col in features_by_auth.get('fake', {}) and feature_col in features_by_auth.get('real', {}):
                        fake_stats = features_by_auth['fake'][feature_col]
                        real_stats = features_by_auth['real'][feature_col]
                        
                        fake_mean = fake_stats.get('mean', 0)
                        real_mean = real_stats.get('mean', 0)
                        fake_std = fake_stats.get('std', 1)
                        real_std = real_stats.get('std', 1)
                        
                        # Cohen's d
                        pooled_std = np.sqrt((fake_std**2 + real_std**2) / 2)
                        effect_size = abs((fake_mean - real_mean) / pooled_std) if pooled_std > 0 else 0
                        
                        discriminative_features.append({
                            'feature': feature_col,
                            'name': feature_name,
                            'effect_size': effect_size,
                            'fake_mean': fake_mean,
                            'real_mean': real_mean
                        })
                
                # Sort by effect size
                discriminative_features = sorted(discriminative_features, key=lambda x: x['effect_size'], reverse=True)
                
                if discriminative_features:
                    # Show top features in a bar chart
                    fig_effect = go.Figure()
                    
                    feature_names = [f['name'] for f in discriminative_features]
                    effect_sizes = [f['effect_size'] for f in discriminative_features]
                    
                    fig_effect.add_trace(go.Bar(
                        y=feature_names,
                        x=effect_sizes,
                        orientation='h',
                        marker_color=CHART_CONFIG['colors']['neutral'],
                        text=[f"{es:.3f}" for es in effect_sizes],
                        textposition='outside'
                    ))
                    
                    fig_effect.update_layout(
                        title="Discriminative Power of Visual Features (Cohen's d)",
                        xaxis_title="Effect Size",
                        yaxis_title="Feature",
                        height=400
                    )
                    st.plotly_chart(fig_effect, use_container_width=True)
                    
                    # Show feature importance table
                    st.markdown("**üèÜ Top Discriminative Features:**")
                    for idx, feat in enumerate(discriminative_features, 1):
                        diff_pct = ((feat['fake_mean'] - feat['real_mean']) / feat['real_mean'] * 100) if feat['real_mean'] != 0 else 0
                        st.write(f"{idx}. **{feat['name']}**: Effect size = {feat['effect_size']:.3f} ({diff_pct:+.1f}% difference)")
                else:
                    st.warning("Insufficient features for discriminative analysis")
                
                # Key visual insights with detailed analysis
                st.subheader("üéØ Key Visual Insights")
                
                # Get features_by_authenticity from summary
                features_by_auth = summary.get('features_by_authenticity', {})
                
                # Calculate feature statistics from pre-computed data
                feature_stats = {}
                for feature_col, feature_name in feature_columns.items():
                    if feature_col in features_by_auth.get('fake', {}) and feature_col in features_by_auth.get('real', {}):
                        fake_stats = features_by_auth['fake'][feature_col]
                        real_stats = features_by_auth['real'][feature_col]
                        
                        fake_mean = fake_stats.get('mean', 0)
                        real_mean = real_stats.get('mean', 0)
                        
                        feature_stats[feature_name] = {
                            'fake_mean': fake_mean,
                            'real_mean': real_mean,
                            'difference_pct': ((fake_mean - real_mean) / real_mean * 100) if real_mean != 0 else 0
                        }
                
                # Create two columns for fake vs real characteristics
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("### üî¥ Fake Image Characteristics")
                    fake_characteristics = []
                    
                    if feature_stats:
                        for feature_name, stats in feature_stats.items():
                            diff_pct = stats['difference_pct']
                            if diff_pct > 2:  # Fake is higher
                                if feature_name == 'Brightness':
                                    fake_characteristics.append(f"‚Ä¢ **Brighter images** ({abs(diff_pct):.1f}% higher) - may indicate artificial enhancement")
                                elif feature_name == 'Sharpness':
                                    fake_characteristics.append(f"‚Ä¢ **Over-sharpened** ({abs(diff_pct):.1f}% higher) - suggests digital manipulation")
                                elif feature_name == 'Visual Entropy':
                                    fake_characteristics.append(f"‚Ä¢ **More complex** ({abs(diff_pct):.1f}% higher) - potentially added artifacts")
                                elif feature_name == 'Noise Level':
                                    fake_characteristics.append(f"‚Ä¢ **Higher noise** ({abs(diff_pct):.1f}% higher) - compression or editing artifacts")
                    
                    # Manipulation score from pre-computed data
                    if 'manipulation_score' in features_by_auth.get('fake', {}) and 'manipulation_score' in features_by_auth.get('real', {}):
                        fake_manipulation = features_by_auth['fake']['manipulation_score'].get('mean', 0)
                        real_manipulation = features_by_auth['real']['manipulation_score'].get('mean', 0)
                        manipulation_diff = ((fake_manipulation - real_manipulation) / real_manipulation) * 100 if real_manipulation != 0 else 0
                        
                        if manipulation_diff > 5:
                            fake_characteristics.append(f"‚Ä¢ **Higher manipulation scores** ({abs(manipulation_diff):.1f}% higher) - detected editing patterns")
                    
                    if fake_characteristics:
                        for char in fake_characteristics:
                            st.markdown(char)
                    else:
                        st.info("No significant distinguishing characteristics detected")
                
                with col2:
                    st.markdown("### üü¢ Real Image Characteristics")
                    real_characteristics = []
                    
                    if feature_stats:
                        for feature_name, stats in feature_stats.items():
                            diff_pct = stats['difference_pct']
                            if diff_pct < -2:  # Real is higher (fake is lower)
                                if feature_name == 'Brightness':
                                    real_characteristics.append(f"‚Ä¢ **Natural brightness** ({abs(diff_pct):.1f}% higher) - unmodified lighting")
                                elif feature_name == 'Sharpness':
                                    real_characteristics.append(f"‚Ä¢ **Natural sharpness** ({abs(diff_pct):.1f}% higher) - authentic image quality")
                                elif feature_name == 'Visual Entropy':
                                    real_characteristics.append(f"‚Ä¢ **Simpler composition** ({abs(diff_pct):.1f}% higher) - natural scenes")
                                elif feature_name == 'Noise Level':
                                    real_characteristics.append(f"‚Ä¢ **Lower noise** ({abs(diff_pct):.1f}% higher) - cleaner captures")
                    
                    # Manipulation score from pre-computed data
                    if 'manipulation_score' in features_by_auth.get('fake', {}) and 'manipulation_score' in features_by_auth.get('real', {}):
                        fake_manipulation = features_by_auth['fake']['manipulation_score'].get('mean', 0)
                        real_manipulation = features_by_auth['real']['manipulation_score'].get('mean', 0)
                        manipulation_diff = ((fake_manipulation - real_manipulation) / real_manipulation) * 100 if real_manipulation != 0 else 0
                        
                        if manipulation_diff < -5:
                            real_characteristics.append(f"‚Ä¢ **Lower manipulation scores** ({abs(manipulation_diff):.1f}% lower) - minimal editing detected")
                    
                    if real_characteristics:
                        for char in real_characteristics:
                            st.markdown(char)
                    else:
                        st.info("No significant distinguishing characteristics detected")
                
                # Summary insight box
                st.markdown("---")
                st.subheader("üí° Visual Analysis Summary")
                
                if feature_stats:
                    # Calculate overall pattern
                    significant_diffs = sum(1 for stats in feature_stats.values() if abs(stats['difference_pct']) > 5)
                    total_features = len(feature_stats)
                    
                    if significant_diffs > 0:
                        st.success(f"""
                        **Key Finding:** {significant_diffs} out of {total_features} visual features show significant differences (>5%) between fake and real images.
                        
                        **Implication:** Visual analysis can contribute to authenticity detection, particularly when combined with other modalities.
                        The detected patterns suggest that fake images often undergo digital manipulation that leaves measurable traces in visual features.
                        """)
                    else:
                        st.info("""
                        **Key Finding:** Visual features show minimal differences between fake and real images in this dataset.
                        
                        **Implication:** Sophisticated fake content may be visually indistinguishable from authentic content, 
                        highlighting the importance of multimodal analysis (combining visual, textual, and social signals).
                        """)
                else:
                    st.warning("Insufficient data for comprehensive visual analysis.")
            
        except FileNotFoundError as e:
            st.error(f"üìÇ Data file not found: {e}")
            st.info("""
            **To generate visual features data:**
            ```bash
            python tasks/run_task8_visual_feature_engineering.py
            ```
            This will extract visual features from images and generate authenticity analysis data.
            """)
        except Exception as e:
            st.error(f"‚ùå Error loading visual features data: {e}")
            st.info("Please ensure visual feature analysis is complete and data files are accessible.")
        finally:
            lazy_loader.hide_section_loading()
