#!/usr/bin/env python3 """ Run Comprehensive Multimodal Exploratory Data Analysis This script executes the complete multimodal EDA pipeline for the Fakeddit dataset, analyzing text, image, and comment data to provide comprehensive insights into misinformation patterns across all modalities. """ import sys import os from pathlib import Path # Add src to path for imports sys.path.append(str(Path(__file__).parent.parent)) from data.multimodal_eda import MultimodalEDA def main(): """Execute the comprehensive multimodal EDA pipeline.""" print("="*80) print("COMPREHENSIVE MULTIMODAL EXPLORATORY DATA ANALYSIS") print("Analyzing Text + Images + Comments + Cross-Modal Relationships") print("="*80) try: # Initialize the multimodal analyzer with real data sources print("\n1. Initializing Multimodal EDA Analyzer...") # Load paths from environment import os from dotenv import load_dotenv load_dotenv() images_dir = os.getenv('IMAGES_FOLDER_PATH') comments_file = os.getenv('COMMENTS_TSV_PATH') print(f" - Images directory: {images_dir}") print(f" - Comments file: {comments_file}") analyzer = MultimodalEDA( data_dir="analysis_results", images_dir=images_dir, comments_file=comments_file ) print("Analyzer initialized with multimodal capabilities") print("2. Loading Multimodal Data Sources...") if not analyzer.load_multimodal_data(): print("Error: Failed to load multimodal data") return False print("Multimodal data loaded successfully") # Analyze text modality print("\n3. Analyzing Text Modality...") text_results = analyzer.analyze_text_modality() if text_results: print("Text analysis completed") print(f" - Analyzed {len(text_results)} text features") else: print("Warning: Text analysis returned no results") # Analyze image modality print("\n4. Analyzing Image Modality...") image_results = analyzer.analyze_image_modality() if image_results: print("Image analysis completed") if 'basic_stats' in image_results: print(f" - Analyzed {image_results['basic_stats']['total_images']} images") else: print("Warning: Image analysis returned no results") # Analyze comments modality print("\n5. Analyzing Comments Modality...") comments_results = analyzer.analyze_comments_modality() if comments_results: print("Comments analysis completed") if 'engagement_stats' in comments_results: print(f" - Analyzed {comments_results['engagement_stats']['total_posts_with_comments']} posts with comments") else: print("Warning: Comments analysis returned no results") # Analyze cross-modal relationships print("\n6. Analyzing Cross-Modal Relationships...") cross_modal_results = analyzer.analyze_cross_modal_relationships() if cross_modal_results: print("Cross-modal analysis completed") print(f" - Identified {len(cross_modal_results)} cross-modal patterns") else: print("Warning: Cross-modal analysis returned no results") # Create comprehensive visualizations print("\n7. Creating Multimodal Visualizations...") viz_success = analyzer.create_multimodal_visualizations("analysis_results") if viz_success: print("Multimodal visualizations created") else: print("Warning: Some visualizations may have failed") # Generate comprehensive report print("\n8. Generating Comprehensive Report...") report_success = analyzer.generate_comprehensive_report("analysis_results") if report_success: print("Comprehensive multimodal report generated") else: print("Warning: Report generation encountered issues") # Display comprehensive summary print("\n" + "="*80) print("MULTIMODAL ANALYSIS SUMMARY") print("="*80) # Dataset overview if analyzer.integrated_data is not None: total_records = len(analyzer.integrated_data) total_features = len(analyzer.integrated_data.columns) print(f"Dataset Overview:") print(f" - Total Records: {total_records:,}") print(f" - Total Features: {total_features}") print(f" - Modalities: Text + Images + Comments") # Text insights if text_results and 'category_patterns' in text_results: print(f"\nText Analysis Insights:") patterns = text_results['category_patterns'] if 'True' in patterns and 'False' in patterns: true_len = patterns['True']['avg_length'] false_len = patterns['False']['avg_length'] diff_pct = ((false_len - true_len) / true_len) * 100 print(f" - False content: {false_len:.1f} avg chars") print(f" - True content: {true_len:.1f} avg chars") print(f" - Difference: {diff_pct:+.1f}% ({'longer' if diff_pct > 0 else 'shorter'} false content)") # Image insights if image_results and 'category_patterns' in image_results: print(f"\nImage Analysis Insights:") patterns = image_results['category_patterns'] if 'True' in patterns and 'False' in patterns: print(f" - True content images: {patterns['True']['count']} analyzed") print(f" - False content images: {patterns['False']['count']} analyzed") if 'avg_quality' in patterns['True'] and 'avg_quality' in patterns['False']: true_quality = patterns['True']['avg_quality'] false_quality = patterns['False']['avg_quality'] quality_diff = ((true_quality - false_quality) / false_quality) * 100 print(f" - Quality difference: {quality_diff:+.1f}% ({'higher' if quality_diff > 0 else 'lower'} for true content)") # Comments insights if comments_results and 'category_patterns' in comments_results: print(f"\nComments Analysis Insights:") patterns = comments_results['category_patterns'] if 'True' in patterns and 'False' in patterns: true_comments = patterns['True']['avg_comments'] false_comments = patterns['False']['avg_comments'] engagement_diff = ((false_comments - true_comments) / true_comments) * 100 print(f" - True content: {true_comments:.1f} avg comments") print(f" - False content: {false_comments:.1f} avg comments") print(f" - Engagement difference: {engagement_diff:+.1f}% ({'higher' if engagement_diff > 0 else 'lower'} for false content)") if 'avg_sentiment' in patterns['True'] and 'avg_sentiment' in patterns['False']: true_sentiment = patterns['True']['avg_sentiment'] false_sentiment = patterns['False']['avg_sentiment'] print(f" - True content sentiment: {true_sentiment:+.3f}") print(f" - False content sentiment: {false_sentiment:+.3f}") # Cross-modal insights if cross_modal_results: print(f"\nCross-Modal Insights:") if 'text_engagement_correlation' in cross_modal_results: corr = cross_modal_results['text_engagement_correlation']['length_comments_correlation'] print(f" - Text length ↔ Engagement correlation: {corr:.3f}") if 'text_image_correlation' in cross_modal_results: corr = cross_modal_results['text_image_correlation']['length_size_correlation'] print(f" - Text length ↔ Image size correlation: {corr:.3f}") # Key findings key_insights = analyzer._generate_key_insights() if key_insights: print(f"\nKey Multimodal Findings:") for insight in key_insights: print(f" - {insight}") # Output files print(f"\nGenerated Outputs (eda_output/):") print(f" - multimodal_eda_report.json (Complete analysis data)") print(f" - MULTIMODAL_EDA_REPORT.md (Human-readable report)") print(f" - multimodal_overview.png (Comprehensive dashboard)") print(f" - cross_modal_analysis.png (Cross-modal relationships)") print(f"\nComprehensive Multimodal EDA completed successfully!") print(f"Ready for multimodal fake news detection model development!") return True except Exception as e: print(f"\nError: Error during multimodal analysis: {e}") import traceback traceback.print_exc() return False if __name__ == "__main__": success = main() sys.exit(0 if success else 1)