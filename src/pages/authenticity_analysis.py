"""
Authenticity Analysis Page
Comprehensive analysis of fake vs real content across all modalities
COMPLETE IMPLEMENTATION - Extracted from app.py
"""
import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from pathlib import Path
from scipy import stats
import sys

sys.path.append(str(Path(__file__).parent.parent.parent))
from src.utils.lazy_loader import LazyLoader

lazy_loader = LazyLoader()


def render_authenticity_analysis(container):
    """Render Authenticity Analysis with lazy loading - COMPLETE IMPLEMENTATION"""
    with container.container():
        try:
            st.header("Fake vs Real Content: Comprehensive Analysis")
            
            st.markdown("""
            **Key Questions Answered:**
            - What distinguishes fake from real content across all modalities?
            - How do engagement patterns differ between authentic and inauthentic posts?
            - What are the statistical signatures of misinformation?
            """)
            
            # Load from JSON summary (FULL dataset with pre-computed visualizations)
            @st.cache_data(ttl=600)  # 10 minutes cache for integrated dataset
            def load_integrated_data():
                import json
                
                summary_path = Path('analysis_results/dashboard_data/authenticity_analysis_summary.json')
                
                if not summary_path.exists():
                    raise FileNotFoundError(f"Authenticity analysis summary not found at {summary_path}")
                
                with open(summary_path, 'r') as f:
                    summary = json.load(f)
                
                return summary
            
            summary = load_integrated_data()
            
            # Extract metadata
            total_count = summary.get('total_records', 0)
            fake_count = summary.get('fake_count', 0)
            real_count = summary.get('real_count', 0)
            
            # Initialize statistical variables at the start
            score_p_value = 1.0
            comment_p_value = 1.0
            score_t_stat = 0.0
            comment_t_stat = 0.0
            
            # Hide loading indicator after data is loaded
            lazy_loader.hide_section_loading()
            
            # Overall authenticity distribution
            st.subheader("ðŸ“Š Authenticity Distribution Across Full Dataset")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("ðŸ”´ Fake Content", f"{fake_count:,}", 
                         delta=f"{fake_count/total_count*100:.1f}% of dataset")
            
            with col2:
                st.metric("ðŸŸ¢ Real Content", f"{real_count:,}", 
                         delta=f"{real_count/total_count*100:.1f}% of dataset")
            
            with col3:
                ratio = fake_count / real_count if real_count > 0 else 0
                st.metric("ðŸ“ˆ Fake:Real Ratio", f"{ratio:.2f}:1")
            
            # Key Insight Box
            st.info(f"""
            **ðŸ” Key Insight:** The dataset shows a significant class imbalance with {fake_count/total_count*100:.1f}% fake content, 
            reflecting the prevalence of misinformation in social media. This {ratio:.1f}:1 ratio provides robust 
            statistical power for detecting authenticity patterns.
            """)
            
            # Authenticity by content modality
            st.subheader("ðŸŽ­ Authenticity Patterns by Content Type")
            
            # Social engagement patterns by authenticity (using pre-computed statistics)
            st.subheader("ðŸ‘¥ Social Engagement: Fake vs Real (Full Dataset)")
            
            metrics_by_auth = summary.get('metrics_by_authenticity', {})
            fake_stats = metrics_by_auth.get('fake', {})
            real_stats = metrics_by_auth.get('real', {})
            
            if 'score' in fake_stats and 'score' in real_stats:
                col1, col2 = st.columns(2)
                
                with col1:
                    # Engagement score comparison
                    fake_score_mean = fake_stats['score'].get('mean', 0)
                    real_score_mean = real_stats['score'].get('mean', 0)
                    
                    fig = go.Figure()
                    fig.add_trace(go.Bar(
                        x=['Fake Content', 'Real Content'],
                        y=[fake_score_mean, real_score_mean],
                        marker_color=['#FF6B6B', '#4ECDC4'],
                        text=[f"{fake_score_mean:.1f}", f"{real_score_mean:.1f}"],
                        textposition='outside'
                    ))
                    fig.update_layout(
                        title=f"Average Engagement Score ({total_count:,} posts)",
                        yaxis_title="Score",
                        height=300
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                with col2:
                    # Comment count comparison
                    fake_comments_mean = fake_stats.get('num_comments', {}).get('mean', 0)
                    real_comments_mean = real_stats.get('num_comments', {}).get('mean', 0)
                    
                    fig = go.Figure()
                    fig.add_trace(go.Bar(
                        x=['Fake Content', 'Real Content'],
                        y=[fake_comments_mean, real_comments_mean],
                        marker_color=['#FF6B6B', '#4ECDC4'],
                        text=[f"{fake_comments_mean:.1f}", f"{real_comments_mean:.1f}"],
                        textposition='outside'
                    ))
                    fig.update_layout(
                        title=f"Average Comment Count ({total_count:,} posts)",
                        yaxis_title="Comments",
                        height=300
                    )
                    st.plotly_chart(fig, use_container_width=True)
                
                # Statistical significance testing (using summary statistics)
                st.subheader("ðŸ“ˆ Statistical Significance (Full Dataset)")
                
                # Calculate t-statistic from summary statistics
                fake_score_std = fake_stats['score'].get('std', 1)
                real_score_std = real_stats['score'].get('std', 1)
                
                se_fake = fake_score_std / (fake_count ** 0.5)
                se_real = real_score_std / (real_count ** 0.5)
                se_diff = (se_fake**2 + se_real**2) ** 0.5
                score_t_stat = (fake_score_mean - real_score_mean) / se_diff if se_diff > 0 else 0
                
                # Approximate p-value
                import numpy as np
                df = fake_count + real_count - 2
                score_p_value = 2 * (1 - stats.t.cdf(abs(score_t_stat), df))
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("**Engagement Score Analysis:**")
                    st.markdown(f"â€¢ T-statistic: {score_t_stat:.3f}")
                    st.markdown(f"â€¢ P-value: {score_p_value:.6f}")
                    if score_p_value < 0.05:
                        st.success("âœ… Statistically significant difference")
                    else:
                        st.warning("âš ï¸ No significant difference")
                
                with col2:
                    st.markdown("**Dataset Coverage:**")
                    st.markdown(f"â€¢ Fake posts: {fake_count:,}")
                    st.markdown(f"â€¢ Real posts: {real_count:,}")
                    st.markdown(f"â€¢ Total analyzed: {total_count:,}")
            
            # Enhanced authenticity insights
            st.subheader("ðŸŽ¯ Comprehensive Authenticity Analysis: Fake vs Real")
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("### ðŸ”´ Fake Content Profile")
                fake_profile = []
                
                # Content distribution
                fake_profile.append(f"**ðŸ“Š Volume:** {fake_count:,} posts ({fake_count/total_count*100:.1f}% of dataset)")
                
                # Engagement pattern
                if 'score' in fake_stats:
                    if fake_score_mean > real_score_mean:
                        engagement_diff = ((fake_score_mean - real_score_mean) / real_score_mean) * 100
                        fake_profile.append(f"**ðŸ‘¥ Engagement:** Higher scores (+{engagement_diff:.1f}%) - potentially sensational")
                    else:
                        engagement_diff = ((real_score_mean - fake_score_mean) / fake_score_mean) * 100
                        fake_profile.append(f"**ðŸ‘¥ Engagement:** Lower scores (-{engagement_diff:.1f}%) - less viral spread")
                    
                    fake_profile.append(f"**ðŸ“ˆ Avg Score:** {fake_score_mean:.1f} points")
                
                # Comment pattern
                if 'num_comments' in fake_stats:
                    if fake_comments_mean > real_comments_mean:
                        comment_diff = ((fake_comments_mean - real_comments_mean) / real_comments_mean) * 100
                        fake_profile.append(f"**ðŸ’¬ Comments:** More discussion (+{comment_diff:.1f}%) - controversial topics")
                    else:
                        comment_diff = ((real_comments_mean - fake_comments_mean) / fake_comments_mean) * 100
                        fake_profile.append(f"**ðŸ’¬ Comments:** Less discussion (-{comment_diff:.1f}%)")
                    
                    fake_profile.append(f"**ðŸ’¬ Avg Comments:** {fake_comments_mean:.1f} per post")
                
                for item in fake_profile:
                    st.markdown(f"â€¢ {item}")
            
            with col2:
                st.markdown("### ðŸŸ¢ Real Content Profile")
                real_profile = []
                
                # Content distribution
                real_profile.append(f"**ðŸ“Š Volume:** {real_count:,} posts ({real_count/total_count*100:.1f}% of dataset)")
                
                # Engagement pattern
                if 'score' in real_stats:
                    if real_score_mean > fake_score_mean:
                        engagement_diff = ((real_score_mean - fake_score_mean) / fake_score_mean) * 100
                        real_profile.append(f"**ðŸ‘¥ Engagement:** Higher scores (+{engagement_diff:.1f}%) - genuine interest")
                    else:
                        engagement_diff = ((fake_score_mean - real_score_mean) / real_score_mean) * 100
                        real_profile.append(f"**ðŸ‘¥ Engagement:** Lower scores (-{engagement_diff:.1f}%) - more subdued")
                    
                    real_profile.append(f"**ðŸ“ˆ Avg Score:** {real_score_mean:.1f} points")
                
                # Comment pattern
                if 'num_comments' in real_stats:
                    if real_comments_mean > fake_comments_mean:
                        comment_diff = ((real_comments_mean - fake_comments_mean) / fake_comments_mean) * 100
                        real_profile.append(f"**ðŸ’¬ Comments:** More discussion (+{comment_diff:.1f}%) - meaningful dialogue")
                    else:
                        comment_diff = ((fake_comments_mean - real_comments_mean) / real_comments_mean) * 100
                        real_profile.append(f"**ðŸ’¬ Comments:** Less discussion (-{comment_diff:.1f}%)")
                    
                    real_profile.append(f"**ðŸ’¬ Avg Comments:** {real_comments_mean:.1f} per post")
                
                for item in real_profile:
                    st.markdown(f"â€¢ {item}")
            
            # Comprehensive summary
            st.markdown("---")
            st.subheader("ðŸ’¡ Authenticity Detection Summary")
            
            # Statistical confidence
            ratio = fake_count / real_count if real_count > 0 else 0
            if score_p_value < 0.05:
                st.success(f"""
                **Statistical Significance:** Detected significant differences between fake and real content (p < 0.05).
                
                **Key Findings:**
                - Fake content represents {fake_count/total_count*100:.1f}% of the dataset ({ratio:.2f}:1 ratio)
                - Social engagement patterns differ significantly between authentic and inauthentic content
                - Analysis based on complete dataset of {total_count:,} posts
                - Multimodal analysis reveals distinct patterns across content types
                
                **Detection Strategy:** Combining social engagement metrics, content modality analysis, and statistical patterns 
                provides a robust framework for authenticity detection. The {ratio:.2f}:1 class imbalance reflects real-world 
                prevalence of misinformation on social media platforms.
                """)
            else:
                st.info(f"""
                **Statistical Significance:** Minimal statistical differences detected between fake and real content.
                
                **Key Findings:**
                - Fake content represents {fake_count/total_count*100:.1f}% of the dataset ({ratio:.2f}:1 ratio)
                - Dataset contains {total_count:,} records across multiple content types
                - Analysis based on lightweight JSON summaries optimized for deployment
                
                **Implication:** Sophisticated misinformation may closely mimic authentic content in social engagement patterns.
                This highlights the importance of multimodal analysis combining visual, textual, and social signals for 
                reliable authenticity detection.
                """)
            
        except FileNotFoundError as e:
            st.error(f"ðŸ“‚ Data file not found: {e}")
            st.info("""
            **To generate the integrated dataset:**
            ```bash
            python tasks/run_task15_final_integration.py
            ```
            This will create the complete multimodal dataset with all features integrated.
            """)
        except Exception as e:
            st.error(f"âŒ Error loading authenticity analysis data: {e}")
            st.info("Please ensure the final integration (Task 15) is complete and the integrated dataset is accessible.")
        finally:
            lazy_loader.hide_section_loading()
