""" Comprehensive Image Analysis Module for Multimodal Fake News Detection This module implements image quality and metadata analysis for the Fakeddit dataset, focusing on identifying visual characteristics and patterns that distinguish between true and false content. Requirements addressed: 2.3, 2.4 (Image Analysis and Visual Authenticity Patterns) """ import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from typing import Dict, List, Tuple, Optional, Any import warnings from pathlib import Path import json from datetime import datetime import os from collections import Counter, defaultdict warnings.filterwarnings('ignore') def convert_to_serializable(obj): """Convert numpy/pandas objects to JSON serializable types.""" if isinstance(obj, np.integer): return int(obj) elif isinstance(obj, np.floating): return float(obj) elif isinstance(obj, np.ndarray): return obj.tolist() elif isinstance(obj, (pd.Series, pd.DataFrame)): return obj.to_dict() elif isinstance(obj, np.bool_): return bool(obj) elif isinstance(obj, dict): return {key: convert_to_serializable(value) for key, value in obj.items()} elif isinstance(obj, list): return [convert_to_serializable(item) for item in obj] elif pd.isna(obj): return None else: return obj # Try to import image processing libraries try: from PIL import Image, ImageStat, ExifTags PIL_AVAILABLE = True except ImportError: PIL_AVAILABLE = False try: import cv2 CV2_AVAILABLE = True except ImportError: CV2_AVAILABLE = False try: from scipy import stats SCIPY_AVAILABLE = True except ImportError: SCIPY_AVAILABLE = False class ImageAnalyzer: """ Comprehensive image analysis for visual pattern mining and authenticity detection. This class analyzes image metadata and quality metrics to identify distinguishing visual characteristics between true and false content. """ def __init__(self, images_dir: str = "processed_data/images", text_data_dir: str = "processed_data/text_data"): """Initialize the image analyzer with processed data directories.""" self.images_dir = Path(images_dir) self.text_data_dir = Path(text_data_dir) self.output_dir = Path("analysis_results") self.viz_dir = Path("visualizations") # Create output directories self.output_dir.mkdir(parents=True, exist_ok=True) self.viz_dir.mkdir(parents=True, exist_ok=True) # Data containers self.text_data = None self.image_metadata = {} self.analysis_results = {} # Category mappings self.binary_mapping = {0: "True", 1: "False"} self.multiway_mapping = {0: "True", 1: "Satire", 2: "Misleading", 3: "False"} # Check library availability self.libraries_available = { 'PIL': PIL_AVAILABLE, 'CV2': CV2_AVAILABLE, 'SCIPY': SCIPY_AVAILABLE } print("Image Analyzer initialized") print(f"Images directory: {self.images_dir}") print(f"Available libraries: {[k for k, v in self.libraries_available.items() if v]}") def load_processed_data(self) -> bool: """ Load processed text data to get record IDs and labels. Returns: bool: True if data loaded successfully """ print("Loading processed text data for image mapping...") try: datasets = [] splits = ['train', 'validation', 'test'] for split in splits: file_path = self.text_data_dir / f"{split}_clean.parquet" if file_path.exists(): df = pd.read_parquet(file_path) df['split'] = split datasets.append(df) print(f"Loaded {split}: {len(df)} records") if datasets: self.text_data = pd.concat(datasets, ignore_index=True) print(f"Combined text data: {len(self.text_data)} total records") # Validate required columns required_cols = ['id', '2_way_label'] missing_cols = [col for col in required_cols if col not in self.text_data.columns] if missing_cols: print(f"Warning: Missing required columns: {missing_cols}") return False return True else: print("Error: No processed data files found") return False except Exception as e: print(f"Error loading processed data: {e}") return False def extract_image_metadata(self, sample_size: int = None) -> Dict[str, Any]: """ Extract comprehensive image metadata and quality metrics. Args: sample_size: Number of images to analyze (None for all) Returns: Dict: Image metadata analysis results """ print("Extracting image metadata and quality metrics...") if self.text_data is None: raise ValueError("Data not loaded. Call load_processed_data() first.") if not PIL_AVAILABLE: print("Warning: PIL not available. Limited image analysis capabilities.") return {} metadata = { 'basic_properties': {}, 'quality_metrics': {}, 'format_analysis': {}, 'category_comparisons': {}, 'processing_stats': {} } available_images = list(self.images_dir.glob("*.jpg")) print(f"Found {len(available_images)} image files") if sample_size and sample_size < len(available_images): available_images = np.random.choice(available_images, sample_size, replace=False) print(f"Sampling {sample_size} images for analysis") # Extract metadata for each image image_data = [] processed_count = 0 error_count = 0 for img_path in available_images: try: # Extract record ID from filename record_id = img_path.stem # Find corresponding label label_row = self.text_data[self.text_data['id'] == record_id] if label_row.empty: continue label = label_row.iloc[0]['2_way_label'] # Extract image metadata img_metadata = self._extract_single_image_metadata(img_path) img_metadata['record_id'] = record_id img_metadata['label'] = label img_metadata['category'] = self.binary_mapping.get(label, f"Category_{label}") image_data.append(img_metadata) processed_count += 1 if processed_count % 500 == 0: print(f"Processed {processed_count} images...") except Exception as e: error_count += 1 continue print(f"Processed {processed_count} images successfully ({error_count} errors)") if image_data: # Convert to DataFrame for analysis df = pd.DataFrame(image_data) # Analyze basic properties metadata['basic_properties'] = self._analyze_basic_properties(df) # Analyze quality metrics metadata['quality_metrics'] = self._analyze_quality_metrics(df) # Analyze format characteristics metadata['format_analysis'] = self._analyze_format_characteristics(df) # Compare categories metadata['category_comparisons'] = self._compare_image_categories(df) # Processing statistics metadata['processing_stats'] = { 'total_processed': processed_count, 'total_errors': error_count, 'success_rate': processed_count / (processed_count + error_count) if (processed_count + error_count) > 0 else 0, 'sample_size': len(available_images) } # Store the DataFrame for later use self.image_metadata = df self.analysis_results['image_metadata'] = metadata print("Image metadata extraction completed") return metadata def _extract_single_image_metadata(self, img_path: Path) -> Dict: """Extract metadata from a single image file.""" metadata = {} try: # Basic file properties file_stats = img_path.stat() metadata['file_size_bytes'] = file_stats.st_size metadata['file_size_kb'] = file_stats.st_size / 1024 metadata['file_size_mb'] = file_stats.st_size / (1024 * 1024) # Open image with PIL with Image.open(img_path) as img: # Basic image properties metadata['width'] = img.width metadata['height'] = img.height metadata['aspect_ratio'] = img.width / img.height if img.height > 0 else 0 metadata['total_pixels'] = img.width * img.height metadata['format'] = img.format metadata['mode'] = img.mode # Calculate megapixels metadata['megapixels'] = metadata['total_pixels'] / 1_000_000 # Image quality metrics if img.mode in ['RGB', 'L']: # Convert to RGB if needed if img.mode != 'RGB': img_rgb = img.convert('RGB') else: img_rgb = img # Calculate image statistics stat = ImageStat.Stat(img_rgb) # Mean values for each channel metadata['mean_red'] = stat.mean[0] if len(stat.mean) > 0 else 0 metadata['mean_green'] = stat.mean[1] if len(stat.mean) > 1 else 0 metadata['mean_blue'] = stat.mean[2] if len(stat.mean) > 2 else 0 metadata['mean_brightness'] = sum(stat.mean) / len(stat.mean) # Standard deviation (measure of contrast) metadata['std_red'] = stat.stddev[0] if len(stat.stddev) > 0 else 0 metadata['std_green'] = stat.stddev[1] if len(stat.stddev) > 1 else 0 metadata['std_blue'] = stat.stddev[2] if len(stat.stddev) > 2 else 0 metadata['mean_contrast'] = sum(stat.stddev) / len(stat.stddev) # Overall image variance (quality indicator) metadata['image_variance'] = stat.var[0] if len(stat.var) > 0 else 0 # EXIF data (if available) exif_data = {} if hasattr(img, '_getexif') and img._getexif(): exif = img._getexif() for tag_id, value in exif.items(): tag = ExifTags.TAGS.get(tag_id, tag_id) exif_data[tag] = value metadata['has_exif'] = len(exif_data) > 0 metadata['exif_tags_count'] = len(exif_data) # Extract specific EXIF fields if available if 'Make' in exif_data: metadata['camera_make'] = str(exif_data['Make']) if 'Model' in exif_data: metadata['camera_model'] = str(exif_data['Model']) if 'DateTime' in exif_data: metadata['datetime_original'] = str(exif_data['DateTime']) except Exception as e: # Set default values on error metadata.update({ 'width': 0, 'height': 0, 'aspect_ratio': 0, 'total_pixels': 0, 'file_size_bytes': 0, 'file_size_kb': 0, 'file_size_mb': 0, 'format': 'unknown', 'mode': 'unknown', 'megapixels': 0, 'mean_brightness': 0, 'mean_contrast': 0, 'image_variance': 0, 'has_exif': False, 'exif_tags_count': 0, 'error': str(e) }) return metadata def _analyze_basic_properties(self, df: pd.DataFrame) -> Dict: """Analyze basic image properties across the dataset.""" print("Analyzing basic image properties...") properties = {} # Overall statistics numeric_cols = ['width', 'height', 'aspect_ratio', 'total_pixels', 'file_size_kb', 'megapixels'] properties['overall'] = {} for col in numeric_cols: if col in df.columns: properties['overall'][col] = { 'mean': float(df[col].mean()), 'median': float(df[col].median()), 'std': float(df[col].std()), 'min': float(df[col].min()), 'max': float(df[col].max()), 'q25': float(df[col].quantile(0.25)), 'q75': float(df[col].quantile(0.75)) } # Format distribution if 'format' in df.columns: format_counts = df['format'].value_counts() properties['format_distribution'] = { format_name: int(count) for format_name, count in format_counts.items() } # Mode distribution if 'mode' in df.columns: mode_counts = df['mode'].value_counts() properties['mode_distribution'] = { mode_name: int(count) for mode_name, count in mode_counts.items() } # Resolution categories if 'total_pixels' in df.columns: df_copy = df.copy() df_copy['resolution_category'] = pd.cut( df_copy['total_pixels'], bins=[0, 500_000, 2_000_000, 8_000_000, float('inf')], labels=['Low (<0.5MP)', 'Medium (0.5-2MP)', 'High (2-8MP)', 'Very High (>8MP)'] ) resolution_counts = df_copy['resolution_category'].value_counts() properties['resolution_distribution'] = { str(res): int(count) for res, count in resolution_counts.items() } return properties def _analyze_quality_metrics(self, df: pd.DataFrame) -> Dict: """Analyze image quality metrics.""" print("Analyzing image quality metrics...") quality = {} # Quality-related columns quality_cols = ['mean_brightness', 'mean_contrast', 'image_variance'] quality['overall'] = {} for col in quality_cols: if col in df.columns and df[col].notna().sum() > 0: quality['overall'][col] = { 'mean': float(df[col].mean()), 'median': float(df[col].median()), 'std': float(df[col].std()), 'min': float(df[col].min()), 'max': float(df[col].max()) } # Quality categories based on contrast (standard deviation) if 'mean_contrast' in df.columns and df['mean_contrast'].notna().sum() > 0: df_copy = df.copy() contrast_threshold_low = df_copy['mean_contrast'].quantile(0.33) contrast_threshold_high = df_copy['mean_contrast'].quantile(0.67) df_copy['quality_category'] = pd.cut( df_copy['mean_contrast'], bins=[0, contrast_threshold_low, contrast_threshold_high, float('inf')], labels=['Low Contrast', 'Medium Contrast', 'High Contrast'] ) quality_counts = df_copy['quality_category'].value_counts() quality['contrast_distribution'] = { str(cat): int(count) for cat, count in quality_counts.items() } # Brightness categories if 'mean_brightness' in df.columns and df['mean_brightness'].notna().sum() > 0: df_copy = df.copy() df_copy['brightness_category'] = pd.cut( df_copy['mean_brightness'], bins=[0, 85, 170, 255], labels=['Dark', 'Medium', 'Bright'] ) brightness_counts = df_copy['brightness_category'].value_counts() quality['brightness_distribution'] = { str(cat): int(count) for cat, count in brightness_counts.items() } return quality def _analyze_format_characteristics(self, df: pd.DataFrame) -> Dict: """Analyze image format and technical characteristics.""" print("Analyzing format characteristics...") format_analysis = {} # File size analysis by format if 'format' in df.columns and 'file_size_kb' in df.columns: format_analysis['size_by_format'] = {} for format_type in df['format'].unique(): if pd.notna(format_type): format_data = df[df['format'] == format_type]['file_size_kb'] if len(format_data) > 0: format_analysis['size_by_format'][format_type] = { 'count': int(len(format_data)), 'mean_size_kb': float(format_data.mean()), 'median_size_kb': float(format_data.median()), 'std_size_kb': float(format_data.std()) } # EXIF data analysis if 'has_exif' in df.columns: exif_count = df['has_exif'].sum() total_count = len(df) format_analysis['exif_analysis'] = { 'images_with_exif': int(exif_count), 'images_without_exif': int(total_count - exif_count), 'exif_percentage': float(exif_count / total_count * 100) if total_count > 0 else 0 } # EXIF tags distribution if 'exif_tags_count' in df.columns: exif_data = df[df['has_exif'] == True]['exif_tags_count'] if len(exif_data) > 0: format_analysis['exif_analysis']['avg_tags_per_image'] = float(exif_data.mean()) format_analysis['exif_analysis']['max_tags'] = int(exif_data.max()) format_analysis['exif_analysis']['min_tags'] = int(exif_data.min()) # Aspect ratio analysis if 'aspect_ratio' in df.columns: # Common aspect ratios df_copy = df.copy() df_copy['aspect_ratio_category'] = df_copy['aspect_ratio'].apply(self._categorize_aspect_ratio) aspect_counts = df_copy['aspect_ratio_category'].value_counts() format_analysis['aspect_ratio_distribution'] = { str(ratio): int(count) for ratio, count in aspect_counts.items() } return format_analysis def _categorize_aspect_ratio(self, ratio: float) -> str: """Categorize aspect ratio into common formats.""" if pd.isna(ratio) or ratio == 0: return 'Unknown' # Common aspect ratios with tolerance tolerance = 0.1 if abs(ratio - 1.0) < tolerance: return 'Square (1:1)' elif abs(ratio - 4/3) < tolerance: return 'Standard (4:3)' elif abs(ratio - 16/9) < tolerance: return 'Widescreen (16:9)' elif abs(ratio - 3/2) < tolerance: return 'Classic (3:2)' elif abs(ratio - 21/9) < tolerance: return 'Ultra-wide (21:9)' elif ratio < 1.0: return 'Portrait' elif ratio > 2.0: return 'Panoramic' else: return 'Other Landscape' def _compare_image_categories(self, df: pd.DataFrame) -> Dict: """Compare image characteristics between true and false content.""" print("Comparing image characteristics by category...") comparisons = {} # Group by category true_data = df[df['label'] == 0] false_data = df[df['label'] == 1] if len(true_data) > 0 and len(false_data) > 0: # Compare numeric features numeric_features = ['width', 'height', 'aspect_ratio', 'file_size_kb', 'megapixels', 'mean_brightness', 'mean_contrast', 'image_variance'] comparisons['statistical_comparisons'] = {} for feature in numeric_features: if feature in df.columns and df[feature].notna().sum() > 10: true_values = true_data[feature].dropna() false_values = false_data[feature].dropna() if len(true_values) > 5 and len(false_values) > 5: comparison = { 'true_content': { 'mean': float(true_values.mean()), 'median': float(true_values.median()), 'std': float(true_values.std()), 'count': int(len(true_values)) }, 'false_content': { 'mean': float(false_values.mean()), 'median': float(false_values.median()), 'std': float(false_values.std()), 'count': int(len(false_values)) } } # Calculate difference mean_diff = false_values.mean() - true_values.mean() comparison['difference'] = { 'absolute': float(mean_diff), 'relative_percent': float(mean_diff / true_values.mean() * 100) if true_values.mean() != 0 else 0 } # Statistical test if scipy available if SCIPY_AVAILABLE: try: stat, p_value = stats.mannwhitneyu(true_values, false_values, alternative='two-sided') comparison['statistical_test'] = { 'statistic': float(stat), 'p_value': float(p_value), 'significant': p_value < 0.05 } except: comparison['statistical_test'] = {'error': 'Could not perform test'} comparisons['statistical_comparisons'][feature] = comparison # Compare categorical features categorical_features = ['format', 'mode', 'has_exif'] comparisons['categorical_comparisons'] = {} for feature in categorical_features: if feature in df.columns: true_dist = true_data[feature].value_counts(normalize=True) false_dist = false_data[feature].value_counts(normalize=True) comparisons['categorical_comparisons'][feature] = { 'true_content': {str(k): float(v) for k, v in true_dist.items()}, 'false_content': {str(k): float(v) for k, v in false_dist.items()} } return comparisons def detect_visual_authenticity_patterns(self) -> Dict[str, Any]: """ Detect visual patterns that distinguish true from false content. Returns: Dict: Visual authenticity pattern analysis results """ print("Detecting visual authenticity patterns...") if not hasattr(self, 'image_metadata') or self.image_metadata.empty: print("Error: No image metadata available. Run extract_image_metadata() first.") return {} patterns = { 'quality_patterns': {}, 'technical_patterns': {}, 'distinguishing_characteristics': {} } df = self.image_metadata # Quality-based patterns patterns['quality_patterns'] = self._analyze_quality_patterns(df) # Technical patterns patterns['technical_patterns'] = self._analyze_technical_patterns(df) # Most distinguishing characteristics patterns['distinguishing_characteristics'] = self._identify_distinguishing_visual_features(df) self.analysis_results['visual_authenticity_patterns'] = patterns print("Visual authenticity pattern detection completed") return patterns def _analyze_quality_patterns(self, df: pd.DataFrame) -> Dict: """Analyze quality-related patterns by authenticity category.""" print("Analyzing quality patterns...") quality_patterns = {} # Group by authenticity true_data = df[df['label'] == 0] false_data = df[df['label'] == 1] if len(true_data) > 0 and len(false_data) > 0: # Brightness patterns if 'mean_brightness' in df.columns and df['mean_brightness'].notna().sum() > 0: quality_patterns['brightness_analysis'] = { 'true_content': { 'avg_brightness': float(true_data['mean_brightness'].mean()), 'brightness_std': float(true_data['mean_brightness'].std()), 'dark_images_percent': float((true_data['mean_brightness'] < 85).mean() * 100), 'bright_images_percent': float((true_data['mean_brightness'] > 170).mean() * 100) }, 'false_content': { 'avg_brightness': float(false_data['mean_brightness'].mean()), 'brightness_std': float(false_data['mean_brightness'].std()), 'dark_images_percent': float((false_data['mean_brightness'] < 85).mean() * 100), 'bright_images_percent': float((false_data['mean_brightness'] > 170).mean() * 100) } } # Contrast patterns if 'mean_contrast' in df.columns and df['mean_contrast'].notna().sum() > 0: quality_patterns['contrast_analysis'] = { 'true_content': { 'avg_contrast': float(true_data['mean_contrast'].mean()), 'contrast_std': float(true_data['mean_contrast'].std()), 'low_contrast_percent': float((true_data['mean_contrast'] < true_data['mean_contrast'].quantile(0.33)).mean() * 100), 'high_contrast_percent': float((true_data['mean_contrast'] > true_data['mean_contrast'].quantile(0.67)).mean() * 100) }, 'false_content': { 'avg_contrast': float(false_data['mean_contrast'].mean()), 'contrast_std': float(false_data['mean_contrast'].std()), 'low_contrast_percent': float((false_data['mean_contrast'] < false_data['mean_contrast'].quantile(0.33)).mean() * 100), 'high_contrast_percent': float((false_data['mean_contrast'] > false_data['mean_contrast'].quantile(0.67)).mean() * 100) } } # Image variance (quality indicator) if 'image_variance' in df.columns and df['image_variance'].notna().sum() > 0: quality_patterns['variance_analysis'] = { 'true_content': { 'avg_variance': float(true_data['image_variance'].mean()), 'variance_std': float(true_data['image_variance'].std()) }, 'false_content': { 'avg_variance': float(false_data['image_variance'].mean()), 'variance_std': float(false_data['image_variance'].std()) } } return quality_patterns def _analyze_technical_patterns(self, df: pd.DataFrame) -> Dict: """Analyze technical patterns by authenticity category.""" print("Analyzing technical patterns...") technical_patterns = {} # Group by authenticity true_data = df[df['label'] == 0] false_data = df[df['label'] == 1] if len(true_data) > 0 and len(false_data) > 0: # Resolution patterns if 'megapixels' in df.columns: technical_patterns['resolution_analysis'] = { 'true_content': { 'avg_megapixels': float(true_data['megapixels'].mean()), 'high_res_percent': float((true_data['megapixels'] > 2.0).mean() * 100), 'low_res_percent': float((true_data['megapixels'] < 0.5).mean() * 100) }, 'false_content': { 'avg_megapixels': float(false_data['megapixels'].mean()), 'high_res_percent': float((false_data['megapixels'] > 2.0).mean() * 100), 'low_res_percent': float((false_data['megapixels'] < 0.5).mean() * 100) } } # File size patterns if 'file_size_kb' in df.columns: technical_patterns['file_size_analysis'] = { 'true_content': { 'avg_size_kb': float(true_data['file_size_kb'].mean()), 'large_files_percent': float((true_data['file_size_kb'] > 500).mean() * 100), 'small_files_percent': float((true_data['file_size_kb'] < 50).mean() * 100) }, 'false_content': { 'avg_size_kb': float(false_data['file_size_kb'].mean()), 'large_files_percent': float((false_data['file_size_kb'] > 500).mean() * 100), 'small_files_percent': float((false_data['file_size_kb'] < 50).mean() * 100) } } # EXIF data patterns if 'has_exif' in df.columns: technical_patterns['exif_analysis'] = { 'true_content': { 'exif_present_percent': float(true_data['has_exif'].mean() * 100), 'avg_exif_tags': float(true_data[true_data['has_exif']]['exif_tags_count'].mean()) if 'exif_tags_count' in df.columns and true_data['has_exif'].sum() > 0 else 0 }, 'false_content': { 'exif_present_percent': float(false_data['has_exif'].mean() * 100), 'avg_exif_tags': float(false_data[false_data['has_exif']]['exif_tags_count'].mean()) if 'exif_tags_count' in df.columns and false_data['has_exif'].sum() > 0 else 0 } } # Aspect ratio patterns if 'aspect_ratio' in df.columns: technical_patterns['aspect_ratio_analysis'] = { 'true_content': { 'avg_aspect_ratio': float(true_data['aspect_ratio'].mean()), 'square_images_percent': float((abs(true_data['aspect_ratio'] - 1.0) < 0.1).mean() * 100), 'wide_images_percent': float((true_data['aspect_ratio'] > 1.5).mean() * 100) }, 'false_content': { 'avg_aspect_ratio': float(false_data['aspect_ratio'].mean()), 'square_images_percent': float((abs(false_data['aspect_ratio'] - 1.0) < 0.1).mean() * 100), 'wide_images_percent': float((false_data['aspect_ratio'] > 1.5).mean() * 100) } } return technical_patterns def _identify_distinguishing_visual_features(self, df: pd.DataFrame) -> Dict: """Identify the most distinguishing visual features between true and false content.""" print("Identifying distinguishing visual features...") features = {} # Group by authenticity true_data = df[df['label'] == 0] false_data = df[df['label'] == 1] if len(true_data) > 0 and len(false_data) > 0: # Calculate effect sizes for different features distinguishing_features = [] numeric_features = ['width', 'height', 'file_size_kb', 'megapixels', 'mean_brightness', 'mean_contrast', 'image_variance', 'aspect_ratio'] for feature in numeric_features: if feature in df.columns and df[feature].notna().sum() > 10: true_values = true_data[feature].dropna() false_values = false_data[feature].dropna() if len(true_values) > 5 and len(false_values) > 5: # Calculate Cohen's d (effect size) pooled_std = np.sqrt(((len(true_values) - 1) * true_values.var() + (len(false_values) - 1) * false_values.var()) / (len(true_values) + len(false_values) - 2)) if pooled_std > 0: cohens_d = abs(true_values.mean() - false_values.mean()) / pooled_std distinguishing_features.append({ 'feature': feature, 'effect_size': float(cohens_d), 'true_mean': float(true_values.mean()), 'false_mean': float(false_values.mean()), 'difference': float(false_values.mean() - true_values.mean()), 'relative_difference_percent': float((false_values.mean() - true_values.mean()) / true_values.mean() * 100) if true_values.mean() != 0 else 0 }) # Sort by effect size distinguishing_features.sort(key=lambda x: x['effect_size'], reverse=True) features['ranked_features'] = distinguishing_features[:10] # Top 10 most distinguishing # Identify the most distinguishing feature if distinguishing_features: top_feature = distinguishing_features[0] features['most_distinguishing'] = { 'feature_name': top_feature['feature'], 'effect_size': top_feature['effect_size'], 'interpretation': self._interpret_effect_size(top_feature['effect_size']), 'difference_description': self._describe_difference(top_feature) } return features def _interpret_effect_size(self, effect_size: float) -> str: """Interpret Cohen's d effect size.""" if effect_size < 0.2: return "negligible" elif effect_size < 0.5: return "small" elif effect_size < 0.8: return "medium" else: return "large" def _describe_difference(self, feature_data: Dict) -> str: """Create a human-readable description of the difference.""" feature = feature_data['feature'] diff = feature_data['difference'] rel_diff = feature_data['relative_difference_percent'] direction = "higher" if diff > 0 else "lower" return f"False content has {direction} {feature} by {abs(rel_diff):.1f}% on average" def create_image_visualizations(self) -> bool: """ Create comprehensive visualizations for image analysis results. Returns: bool: True if visualizations created successfully """ print("Creating image analysis visualizations...") if not self.analysis_results or not hasattr(self, 'image_metadata'): print("Error: No analysis results available. Run analysis first.") return False try: # Set up plotting style plt.style.use('default') sns.set_palette("husl") # 1. Basic properties comparison self._create_basic_properties_visualization() # 2. Quality metrics comparison self._create_quality_metrics_visualization() # 3. Format and technical characteristics self._create_format_characteristics_visualization() # 4. Distinguishing features visualization self._create_distinguishing_visual_features_visualization() print("Image analysis visualizations created successfully") return True except Exception as e: print(f"Error creating visualizations: {e}") return False def _create_basic_properties_visualization(self): """Create basic image properties comparison visualization.""" if not hasattr(self, 'image_metadata') or self.image_metadata.empty: return df = self.image_metadata fig, axes = plt.subplots(2, 3, figsize=(18, 12)) fig.suptitle('Image Properties Comparison by Category', fontsize=16, fontweight='bold') # Group by category true_data = df[df['label'] == 0] false_data = df[df['label'] == 1] categories = ['True', 'False'] # File size comparison if 'file_size_kb' in df.columns: sizes = [true_data['file_size_kb'].mean(), false_data['file_size_kb'].mean()] axes[0, 0].bar(categories, sizes, color=['skyblue', 'lightcoral']) axes[0, 0].set_title('Average File Size') axes[0, 0].set_ylabel('Size (KB)') # Resolution comparison if 'megapixels' in df.columns: resolutions = [true_data['megapixels'].mean(), false_data['megapixels'].mean()] axes[0, 1].bar(categories, resolutions, color=['lightgreen', 'orange']) axes[0, 1].set_title('Average Resolution') axes[0, 1].set_ylabel('Megapixels') # Aspect ratio comparison if 'aspect_ratio' in df.columns: ratios = [true_data['aspect_ratio'].mean(), false_data['aspect_ratio'].mean()] axes[0, 2].bar(categories, ratios, color=['gold', 'pink']) axes[0, 2].set_title('Average Aspect Ratio') axes[0, 2].set_ylabel('Width/Height Ratio') # Brightness comparison if 'mean_brightness' in df.columns: brightness = [true_data['mean_brightness'].mean(), false_data['mean_brightness'].mean()] axes[1, 0].bar(categories, brightness, color=['lightblue', 'lightcoral']) axes[1, 0].set_title('Average Brightness') axes[1, 0].set_ylabel('Brightness (0-255)') # Contrast comparison if 'mean_contrast' in df.columns: contrast = [true_data['mean_contrast'].mean(), false_data['mean_contrast'].mean()] axes[1, 1].bar(categories, contrast, color=['lightcyan', 'lightsalmon']) axes[1, 1].set_title('Average Contrast') axes[1, 1].set_ylabel('Contrast (Std Dev)') # EXIF presence comparison if 'has_exif' in df.columns: exif_presence = [true_data['has_exif'].mean() * 100, false_data['has_exif'].mean() * 100] axes[1, 2].bar(categories, exif_presence, color=['lightsteelblue', 'mistyrose']) axes[1, 2].set_title('EXIF Data Presence') axes[1, 2].set_ylabel('Percentage with EXIF') plt.tight_layout() plt.savefig(self.viz_dir / 'image_basic_properties.png', dpi=300, bbox_inches='tight') plt.close() def _create_quality_metrics_visualization(self): """Create quality metrics visualization.""" if not hasattr(self, 'image_metadata') or self.image_metadata.empty: return df = self.image_metadata fig, axes = plt.subplots(2, 2, figsize=(15, 10)) fig.suptitle('Image Quality Metrics by Category', fontsize=16, fontweight='bold') # Group by category true_data = df[df['label'] == 0] false_data = df[df['label'] == 1] # Brightness distribution if 'mean_brightness' in df.columns and df['mean_brightness'].notna().sum() > 0: axes[0, 0].hist(true_data['mean_brightness'].dropna(), alpha=0.7, label='True', bins=30, color='skyblue') axes[0, 0].hist(false_data['mean_brightness'].dropna(), alpha=0.7, label='False', bins=30, color='lightcoral') axes[0, 0].set_title('Brightness Distribution') axes[0, 0].set_xlabel('Mean Brightness') axes[0, 0].set_ylabel('Frequency') axes[0, 0].legend() # Contrast distribution if 'mean_contrast' in df.columns and df['mean_contrast'].notna().sum() > 0: axes[0, 1].hist(true_data['mean_contrast'].dropna(), alpha=0.7, label='True', bins=30, color='lightgreen') axes[0, 1].hist(false_data['mean_contrast'].dropna(), alpha=0.7, label='False', bins=30, color='orange') axes[0, 1].set_title('Contrast Distribution') axes[0, 1].set_xlabel('Mean Contrast') axes[0, 1].set_ylabel('Frequency') axes[0, 1].legend() # File size distribution if 'file_size_kb' in df.columns: axes[1, 0].hist(true_data['file_size_kb'].dropna(), alpha=0.7, label='True', bins=30, color='gold') axes[1, 0].hist(false_data['file_size_kb'].dropna(), alpha=0.7, label='False', bins=30, color='pink') axes[1, 0].set_title('File Size Distribution') axes[1, 0].set_xlabel('File Size (KB)') axes[1, 0].set_ylabel('Frequency') axes[1, 0].legend() # Resolution distribution if 'megapixels' in df.columns: axes[1, 1].hist(true_data['megapixels'].dropna(), alpha=0.7, label='True', bins=30, color='lightblue') axes[1, 1].hist(false_data['megapixels'].dropna(), alpha=0.7, label='False', bins=30, color='lightcoral') axes[1, 1].set_title('Resolution Distribution') axes[1, 1].set_xlabel('Megapixels') axes[1, 1].set_ylabel('Frequency') axes[1, 1].legend() plt.tight_layout() plt.savefig(self.viz_dir / 'image_quality_distributions.png', dpi=300, bbox_inches='tight') plt.close() def _create_format_characteristics_visualization(self): """Create format characteristics visualization.""" if 'image_metadata' not in self.analysis_results: return format_data = self.analysis_results['image_metadata']['format_analysis'] fig, axes = plt.subplots(2, 2, figsize=(15, 10)) fig.suptitle('Image Format Characteristics', fontsize=16, fontweight='bold') # Format distribution if 'format_distribution' in self.analysis_results['image_metadata']['basic_properties']: format_dist = self.analysis_results['image_metadata']['basic_properties']['format_distribution'] formats = list(format_dist.keys()) counts = list(format_dist.values()) axes[0, 0].pie(counts, labels=formats, autopct='%1.1f%%', startangle=90) axes[0, 0].set_title('Image Format Distribution') # Resolution categories if 'resolution_distribution' in self.analysis_results['image_metadata']['basic_properties']: res_dist = self.analysis_results['image_metadata']['basic_properties']['resolution_distribution'] resolutions = list(res_dist.keys()) res_counts = list(res_dist.values()) axes[0, 1].bar(resolutions, res_counts, color=['lightblue', 'lightgreen', 'orange', 'lightcoral']) axes[0, 1].set_title('Resolution Categories') axes[0, 1].set_ylabel('Count') axes[0, 1].tick_params(axis='x', rotation=45) # Aspect ratio distribution if 'aspect_ratio_distribution' in format_data: aspect_dist = format_data['aspect_ratio_distribution'] aspects = list(aspect_dist.keys()) aspect_counts = list(aspect_dist.values()) axes[1, 0].bar(aspects, aspect_counts, color='lightsteelblue') axes[1, 0].set_title('Aspect Ratio Distribution') axes[1, 0].set_ylabel('Count') axes[1, 0].tick_params(axis='x', rotation=45) # EXIF data presence if 'exif_analysis' in format_data: exif_data = format_data['exif_analysis'] exif_labels = ['With EXIF', 'Without EXIF'] exif_counts = [exif_data['images_with_exif'], exif_data['images_without_exif']] axes[1, 1].pie(exif_counts, labels=exif_labels, autopct='%1.1f%%', startangle=90, colors=['lightgreen', 'lightcoral']) axes[1, 1].set_title('EXIF Data Presence') plt.tight_layout() plt.savefig(self.viz_dir / 'image_format_characteristics.png', dpi=300, bbox_inches='tight') plt.close() def _create_distinguishing_visual_features_visualization(self): """Create visualization for distinguishing visual features.""" if 'visual_authenticity_patterns' not in self.analysis_results: return patterns = self.analysis_results['visual_authenticity_patterns'] if 'distinguishing_characteristics' in patterns and 'ranked_features' in patterns['distinguishing_characteristics']: features_data = patterns['distinguishing_characteristics']['ranked_features'] if features_data: fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6)) fig.suptitle('Most Distinguishing Visual Features', fontsize=16, fontweight='bold') # Top features by effect size top_features = features_data[:8] # Top 8 features feature_names = [f['feature'] for f in top_features] effect_sizes = [f['effect_size'] for f in top_features] ax1.barh(feature_names, effect_sizes, color='lightsteelblue') ax1.set_title('Feature Discriminative Power (Effect Size)') ax1.set_xlabel('Cohen\'s d (Effect Size)') ax1.invert_yaxis() # Add effect size interpretation for i, (name, size) in enumerate(zip(feature_names, effect_sizes)): interpretation = self._interpret_effect_size(size) ax1.text(size + 0.01, i, f'({interpretation})', va='center', fontsize=9) # Difference visualization for top 5 features top_5_features = features_data[:5] feature_names_short = [f['feature'].replace('_', ' ').title() for f in top_5_features] true_means = [f['true_mean'] for f in top_5_features] false_means = [f['false_mean'] for f in top_5_features] x = np.arange(len(feature_names_short)) width = 0.35 ax2.bar(x - width/2, true_means, width, label='True Content', color='skyblue', alpha=0.8) ax2.bar(x + width/2, false_means, width, label='False Content', color='lightcoral', alpha=0.8) ax2.set_title('Mean Values Comparison (Top 5 Features)') ax2.set_xlabel('Features') ax2.set_ylabel('Mean Value') ax2.set_xticks(x) ax2.set_xticklabels(feature_names_short, rotation=45, ha='right') ax2.legend() plt.tight_layout() plt.savefig(self.viz_dir / 'distinguishing_visual_features.png', dpi=300, bbox_inches='tight') plt.close() def save_analysis_results(self, filename: str = None) -> bool: """ Save comprehensive analysis results to JSON file. Args: filename: Custom filename for results (optional) Returns: bool: True if saved successfully """ if not self.analysis_results: print("Error: No analysis results to save") return False try: if filename is None: timestamp = datetime.now().strftime("%Y%m%d_%H%M%S") filename = f"image_analysis_results_{timestamp}.json" filepath = self.output_dir / filename # Add metadata to results results_with_metadata = { 'metadata': { 'analysis_timestamp': datetime.now().isoformat(), 'total_images_analyzed': len(self.image_metadata) if hasattr(self, 'image_metadata') else 0, 'libraries_used': [k for k, v in self.libraries_available.items() if v], 'analysis_version': '1.0' }, 'results': convert_to_serializable(self.analysis_results) } with open(filepath, 'w', encoding='utf-8') as f: json.dump(results_with_metadata, f, indent=2, ensure_ascii=False) print(f"Analysis results saved to: {filepath}") return True except Exception as e: print(f"Error saving results: {e}") return False def generate_summary_report(self) -> str: """ Generate a comprehensive summary report of image analysis findings. Returns: str: Formatted summary report """ if not self.analysis_results: return "No analysis results available. Please run the analysis first." report = [] report.append("=" * 80) report.append("IMAGE ANALYSIS SUMMARY REPORT") report.append("=" * 80) report.append(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}") report.append("") # Dataset overview if hasattr(self, 'image_metadata') and not self.image_metadata.empty: df = self.image_metadata true_count = len(df[df['label'] == 0]) false_count = len(df[df['label'] == 1]) report.append("DATASET OVERVIEW") report.append("-" * 40) report.append(f"Total images analyzed: {len(df):,}") report.append(f"True content images: {true_count:,} ({true_count/len(df)*100:.1f}%)") report.append(f"False content images: {false_count:,} ({false_count/len(df)*100:.1f}%)") report.append("") # Key findings from visual authenticity patterns if 'visual_authenticity_patterns' in self.analysis_results: patterns = self.analysis_results['visual_authenticity_patterns'] report.append("KEY VISUAL AUTHENTICITY FINDINGS") report.append("-" * 40) # Most distinguishing feature if ('distinguishing_characteristics' in patterns and 'most_distinguishing' in patterns['distinguishing_characteristics']): most_dist = patterns['distinguishing_characteristics']['most_distinguishing'] report.append(f"Most distinguishing feature: {most_dist['feature_name']}") report.append(f"Effect size: {most_dist['effect_size']:.3f} ({most_dist['interpretation']})") report.append(f"Finding: {most_dist['difference_description']}") report.append("") # Quality patterns summary if 'quality_patterns' in patterns: quality = patterns['quality_patterns'] report.append("IMAGE QUALITY PATTERNS") report.append("-" * 30) if 'brightness_analysis' in quality: brightness = quality['brightness_analysis'] true_bright = brightness['true_content']['avg_brightness'] false_bright = brightness['false_content']['avg_brightness'] report.append(f"Average brightness - True: {true_bright:.1f}, False: {false_bright:.1f}") if 'contrast_analysis' in quality: contrast = quality['contrast_analysis'] true_contrast = contrast['true_content']['avg_contrast'] false_contrast = contrast['false_content']['avg_contrast'] report.append(f"Average contrast - True: {true_contrast:.1f}, False: {false_contrast:.1f}") report.append("") # Technical patterns summary if 'technical_patterns' in patterns: technical = patterns['technical_patterns'] report.append("TECHNICAL CHARACTERISTICS") report.append("-" * 30) if 'resolution_analysis' in technical: resolution = technical['resolution_analysis'] true_mp = resolution['true_content']['avg_megapixels'] false_mp = resolution['false_content']['avg_megapixels'] report.append(f"Average resolution - True: {true_mp:.2f}MP, False: {false_mp:.2f}MP") if 'file_size_analysis' in technical: file_size = technical['file_size_analysis'] true_size = file_size['true_content']['avg_size_kb'] false_size = file_size['false_content']['avg_size_kb'] report.append(f"Average file size - True: {true_size:.1f}KB, False: {false_size:.1f}KB") if 'exif_analysis' in technical: exif = technical['exif_analysis'] true_exif = exif['true_content']['exif_present_percent'] false_exif = exif['false_content']['exif_present_percent'] report.append(f"EXIF data presence - True: {true_exif:.1f}%, False: {false_exif:.1f}%") report.append("") # Processing statistics if 'image_metadata' in self.analysis_results: metadata = self.analysis_results['image_metadata'] if 'processing_stats' in metadata: stats = metadata['processing_stats'] report.append("PROCESSING STATISTICS") report.append("-" * 30) report.append(f"Images processed successfully: {stats['total_processed']:,}") report.append(f"Processing errors: {stats['total_errors']:,}") report.append(f"Success rate: {stats['success_rate']*100:.1f}%") report.append("") report.append("=" * 80) return "\n".join(report) def run_complete_analysis(self, sample_size: int = None) -> bool: """ Run the complete image analysis pipeline. Args: sample_size: Number of images to analyze (None for all) Returns: bool: True if analysis completed successfully """ print("Starting complete image analysis pipeline...") try: if not self.load_processed_data(): return False metadata_results = self.extract_image_metadata(sample_size=sample_size) if not metadata_results: print("Error: Failed to extract image metadata") return False pattern_results = self.detect_visual_authenticity_patterns() if not pattern_results: print("Error: Failed to detect visual patterns") return False if not self.create_image_visualizations(): print("Warning: Some visualizations may have failed") if not self.save_analysis_results(): print("Warning: Failed to save results") summary = self.generate_summary_report() summary_path = self.output_dir / "image_analysis_summary.txt" with open(summary_path, 'w', encoding='utf-8') as f: f.write(summary) print("Complete image analysis pipeline finished successfully!") print(f"Results saved to: {self.output_dir}") print(f"Visualizations saved to: {self.viz_dir}") print(f"Summary report: {summary_path}") return True except Exception as e: print(f"Error in complete analysis pipeline: {e}") return False def main(): """Main function to run image analysis.""" print("Multimodal Fake News Detection - Image Analysis") print("=" * 60) analyzer = ImageAnalyzer() success = analyzer.run_complete_analysis(sample_size=None) if success: print("\n" + analyzer.generate_summary_report()) else: print("Analysis failed. Please check the error messages above.") if __name__ == "__main__": main()