#!/usr/bin/env python3 """ Run Exploratory Data Analysis This script executes comprehensive exploratory data analysis on the clean Fakeddit dataset, generating descriptive statistics, visualizations, and analytical reports. """ import sys import os from pathlib import Path # Add src to path for imports sys.path.append(str(Path(__file__).parent.parent)) from data.exploratory_analysis import ExploratoryAnalyzer def main(): """Execute the exploratory data analysis pipeline.""" print("="*60) print("EXPLORATORY DATA ANALYSIS - FAKEDDIT DATASET") print("="*60) try: # Initialize the analyzer print("\n1. Initializing Exploratory Data Analyzer...") analyzer = ExploratoryAnalyzer(data_dir="processed_data") # Load clean datasets print("\n2. Loading clean datasets...") if not analyzer.load_clean_datasets(): print("Error: Failed to load datasets. Please ensure clean datasets exist in processed_data/") return False # Create output directory output_dir = "eda_output" Path(output_dir).mkdir(exist_ok=True) print(f"Output directory created: {output_dir}/") # Generate descriptive statistics print("\n3. Generating descriptive statistics...") stats = analyzer.generate_descriptive_statistics() print("Descriptive statistics generated") # Analyze category patterns print("\n4. Analyzing category-specific patterns...") patterns = analyzer.analyze_category_patterns() print("Category patterns analyzed") # Create visualizations print("\n5. Creating visualizations...") if analyzer.create_visualizations(output_dir): print("Visualizations created successfully") else: print("Warning: Some visualizations may have failed") # Generate comprehensive report print("\n6. Generating comprehensive report...") if analyzer.generate_comprehensive_report(output_dir): print("Comprehensive report generated") else: print("Warning: Report generation may have encountered issues") # Display summary print("\n" + "="*60) print("ANALYSIS SUMMARY") print("="*60) print(f"Total records analyzed: {stats['dataset_overview']['total_records']:,}") print(f"Dataset memory usage: {stats['dataset_overview']['memory_usage_mb']:.2f} MB") print(f"Features analyzed: {stats['dataset_overview']['total_features']}") # Split distribution print(f"\nSplit Distribution:") for split, count in stats['dataset_overview']['split_distribution'].items(): percentage = (count / stats['dataset_overview']['total_records']) * 100 print(f" - {split.capitalize()}: {count:,} records ({percentage:.1f}%)") # Category distribution if 'category_distribution' in stats: print(f"\nCategory Distribution (Binary):") for category, count in stats['category_distribution']['overall'].items(): category_name = "True" if category == 0 else "False" percentage = (count / stats['dataset_overview']['total_records']) * 100 print(f" - {category_name}: {count:,} records ({percentage:.1f}%)") # Text analysis summary if 'text_analysis' in stats: print(f"\nText Content Summary:") for col, text_stats in stats['text_analysis'].items(): print(f" - {col}: Avg {text_stats['avg_length']:.0f} chars, " f"Max {text_stats['max_length']:,} chars") # Data quality overview if 'data_quality' in stats: missing_cols = sum(1 for count in stats['data_quality']['missing_values_by_column'].values() if count > 0) duplicate_count = stats['data_quality']['duplicate_rows'] print(f"\nData Quality:") print(f" - Columns with missing values: {missing_cols}") print(f" - Duplicate rows: {duplicate_count}") print(f"\nAll results saved to: {output_dir}/") print(" - EDA_REPORT.md (Comprehensive markdown report)") print(" - eda_comprehensive_report.json (Detailed JSON data)") print(" - Various visualization PNG files") print("\nExploratory Data Analysis completed successfully!") return True except Exception as e: print(f"\nError: Error during exploratory analysis: {e}") import traceback traceback.print_exc() return False if __name__ == "__main__": success = main() sys.exit(0 if success else 1)